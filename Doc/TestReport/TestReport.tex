\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}

\input{../Comments}

\begin{document}

\title{Test Report: Project Title} 
\author{Author Name}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
Date 1 & 1.0 & Notes\\
Date 2 & 1.1 & Notes\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l} 
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 
  T & Test\\
  \bottomrule
\end{tabular}\\

\wss{symbols, abbreviations or acronyms -- you can reference the SRS tables if needed}

\newpage

\tableofcontents

\listoftables %if appropriate

\listoffigures %if appropriate

\newpage

\pagenumbering{arabic}

This document provides a testing report of Stock Prediction System. This document covers both system testing and unit testing.
 Traceability between testing and both requirements and modules
is given in the final section. The implementation of the tests in this
report follows the Test Plan document. For more information please view my documentation at the repository:
 \url{https://github.com/renjiezhang/CAS-741}\\

\section{Functional Requirements Evaluation}
\subsection{Data Input}
The part of test is to verify the loading a dataset from a CSV file. This test ensures the data input method and the input data. 

\paragraph{File loading Testing }

\begin{enumerate}

\item{File is loaded successfully\\}

Type: Functional, Manual, Static\\
Initial State: NA\\
Input: File Path\\
Output: Successful Message\\
How test will be performed: System tries to load the data set file based on the file name and location without issues.\\
Result : Pass\\
\item{Input Data Validation\\}

Type: Functional, Manual\\
Initial State: NA\\
Input: Data from the file\\
Output: A successful message.\\
How test will be performed: System have to ensure the data type and format is
correct for each columns of the file : the pattern of the date, the formats
of the price and number of digits of decimals. If the format does match the requirement, the program will encounter an IO exception.
The example of the CSV file is shown in the following figure. \\
Result: Pass\\

\end{enumerate}

\subsubsection{Distributed System}
This section focus on the distributed system of Spark platform. It guides the
users to test the data flow on the spark system. RDD is the format of data flow
in Spark. testers need to double check the data was distributed into each
workers through RDD.

\paragraph{ Spark RDD Testing}
~\newline

%\begin{enumerate}

%\item{Data is distributed to workers\\}

Type: Functional, Manual, Static\\
Initial State: NA\\
Input:There will be a list of numbers to input to the RDD function. To test the RDD function, the driver will ask Spark to return some random number back. \\
Output: The list of numbers which is collected back from workers.\\
How test will be performed: There will be an input array to the driver, driver assign the array to each workers. Each worker receives part of the numbers in the list. When the driver collect the RDD, works return each part of the number back to driver. A sample work flow is shown below:
~\newline


%\end{enumerate}


\section{Nonfunctional Requirements Evaluation}

\subsection{Usability}
		
\subsection{Performance}
Type: Manual
Initial State: NA
Input/Condition: NA
Output/Result: Result of the time cost\\
How test will be performed: \\
Chang the size of the dataset files by downloading the files with different date range. For example, reduce the date range from 5 years to 3 years and compare the performance. \\
Change the number of date parameter to predict short term and long term stock price. By adding a new type of number of date, the software need to increase the run time. \\
\subsection{etc.}
	
\section{Comparison to Existing Implementation}	

NA

\section{Unit Testing}

The unit testing plan will involve the following modules: Load Data, SVM Kernelling, Volatility Calculating, Momentum Calculating, Predict and Output.\\
\begin{enumerate}

\item{ Calculate Volatility\\}
This function is use to calculate the price volatility and index volatility. Since the calculation is similar they share the same function. A correct result is expected by inputting the parameters to the equation \\
$\frac{\sum_{i=t-n+1}^{t} \frac{C_i-C_{i-1}}{C{i-1}}}{n}$ \\ 

Input: A pre-defined Array of stock record, which contains two elements: price and date\\
Output: An array of price volatility based on the input array\\


\item{ Calculate Momentum\\}
This function is use to calculate the price momentum and index momentum. Since the calculation is similar they share the same function. A correct result is expected by inputting the parameters to the equation \\
$\frac{\sum_{i=t-n+1}^{t} \frac{C_i-C_{i-1}}{C{i-1}}}{n}$ \\ 

Input: A pre-defined Array of stock record, which contains two elements: price and date\\
Output: An array of price volatility based on the input array\\


\item{Predict \\}
The Predict module receives a set of parameters calculated from the previous functions and returns a result. A correct result is expected by inputing the parameters to the equation \\\\
$y=\beta _0+\sum {a_iy_iK(x(i),x)}$\\
Input: Two pre-defined lists of stock record, which contains two elements: price and date. They have same format, one is for stock price and another is for NASDQ Index record\\
Output:A score of a decimal number which represents the probability\\

\item{Plot Testing\\}
Type: Functional, Manual, Static
Initial State: NA\\
Input: A pre-defined Array\\
Output: A correct plot\\
How test will be performed: System reads the data and generate a plot using the price and the date as the x and y axis.\\
result : Pass\\
\end{enumerate} 
\section{Changes Due to Testing}
The test on multiple spark workers are removed due to the limit time because  I have encountered some problems with configuration of multiple Docker containers. The system for now is on a single node spark machine.
\section{Automated Testing}
		
\section{Trace to Requirements}
		
\section{Trace to Modules}		

\section{Code Coverage Metrics}

\bibliographystyle{plainnat}

\bibliography{SRS}

\end{document}
